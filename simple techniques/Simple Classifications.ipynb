{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from collections import namedtuple, defaultdict\n",
    "import inspect\n",
    "import configparser\n",
    "from prettytable import PrettyTable\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "config_dict = {section: dict(config[section]) for section in config.sections()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    \"max_iter\": ast.literal_eval(config[\"CLASSIFICATION\"][\"maxiterations\"]),\n",
    "    \"cv\": ast.literal_eval(config[\"CLASSIFICATION\"][\"cvfolds\"]),\n",
    "    \"tolerance\": ast.literal_eval(config[\"CLASSIFICATION\"][\"tolerance\"]),\n",
    "    \"random_state\": ast.literal_eval(config[\"CLASSIFICATION\"][\"randomstate\"]),\n",
    "    \"verbose\": ast.literal_eval(config[\"CLASSIFICATION\"][\"verbose\"]),\n",
    "}\n",
    "\n",
    "model_parameters = defaultdict(lambda: None, model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classification Models\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "1. `LogisticRegression`: Logistic Regression (aka logit, MaxEnt) classifier.\n",
    "\n",
    "2. `SGDClassifier`: Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n",
    "\n",
    "3. `Perceptron`: The perceptron is a simple classification algorithm suitable for large scale learning.\n",
    "\n",
    "4. `PassiveAggressiveClassifier`: Passive Aggressive Classifier.\n",
    "\n",
    "5. `RidgeClassifier`: Classifier using Ridge regression.\n",
    "\n",
    "6. `RidgeClassifierCV`: Ridge classifier with built-in cross-validation.\n",
    "\n",
    "7. `LinearSVC`: Linear Support Vector Classification.\n",
    "\n",
    "8. `SVC`: C-Support Vector Classification.\n",
    "\n",
    "9. `NuSVC`: Nu-Support Vector Classification.\n",
    "\n",
    "10. `DecisionTreeClassifier`: A decision tree classifier.\n",
    "\n",
    "11. `RandomForestClassifier`: A random forest classifier.\n",
    "\n",
    "12. `ExtraTreesClassifier`: An extra-trees classifier.\n",
    "\n",
    "13. `GradientBoostingClassifier`: Gradient Boosting for classification.\n",
    "\n",
    "14. `HistGradientBoostingClassifier`: Histogram-based Gradient Boosting Classification Tree.\n",
    "\n",
    "15. `AdaBoostClassifier`: An AdaBoost classifier.\n",
    "\n",
    "16. `BaggingClassifier`: A Bagging classifier.\n",
    "\n",
    "17. `VotingClassifier`: Soft Voting/Majority Rule classifier for unfitted estimators.\n",
    "\n",
    "18. `StackingClassifier`: Stacking classifier for unfitted estimators.\n",
    "\n",
    "19. `KNeighborsClassifier`: Classifier implementing the k-nearest neighbors vote.\n",
    "\n",
    "20. `RadiusNeighborsClassifier`: Classifier implementing a vote among neighbors within a given radius.\n",
    "\n",
    "21. `MLPClassifier`: Multi-layer Perceptron classifier.\n",
    "\n",
    "22. `GaussianNB`: Gaussian Naive Bayes (GaussianNB).\n",
    "\n",
    "23. `BernoulliNB`: Naive Bayes classifier for multivariate Bernoulli models.\n",
    "\n",
    "24. `ComplementNB`: The Complement Naive Bayes classifier.\n",
    "\n",
    "25. `MultinomialNB`: Naive Bayes classifier for multinomial models.\n",
    "\n",
    "Please refer to the [Scikit-learn documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) for more details on each of these methods.\n",
    "\n",
    "\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "iris_df = load_breast_cancer(as_frame=True).frame\n",
    "\n",
    "y = iris_df.pop('target').values\n",
    "X_df = iris_df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for column in X_df.columns:\n",
    "    X_df[column] = scaler.fit_transform(X_df[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_df.values, y, test_size=0.3, random_state=42)\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X, test_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier, Perceptron, PassiveAggressiveClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_appropriate_kwargs(function):\n",
    "    signature = inspect.signature(function)\n",
    "    parameters = signature.parameters\n",
    "    keywords = {k: v.default for k, v in parameters.items() if v.default is not inspect.Parameter.empty}\n",
    "\n",
    "    for key, _ in keywords.items():\n",
    "        if key in model_parameters:\n",
    "            keywords[key] = model_parameters[key]\n",
    "\n",
    "    return partial(function, **keywords)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics = namedtuple('model_and_metrics', ['model', 'accuracy', 'log_loss', 'confusion_matrix'])\n",
    "\n",
    "def train_model(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    cm = confusion_matrix(test_y, pred_y)\n",
    "    return model_and_metrics(model, accuracy_score(test_y, pred_y), log_loss(test_y, pred_y), cm)\n",
    "\n",
    "models = [\n",
    "    LogisticRegressionCV,\n",
    "    SGDClassifier,\n",
    "    Perceptron,\n",
    "    PassiveAggressiveClassifier,\n",
    "    RidgeClassifierCV,\n",
    "    LinearSVC,\n",
    "    SVC,\n",
    "    NuSVC,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    MLPClassifier,\n",
    "    GaussianNB,\n",
    "    BernoulliNB,\n",
    "]\n",
    "\n",
    "curried_models = [add_appropriate_kwargs(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Cs': 10,\n",
       "  'fit_intercept': True,\n",
       "  'cv': None,\n",
       "  'dual': False,\n",
       "  'penalty': 'l2',\n",
       "  'scoring': None,\n",
       "  'solver': 'lbfgs',\n",
       "  'tol': 0.0001,\n",
       "  'max_iter': 100,\n",
       "  'class_weight': None,\n",
       "  'n_jobs': None,\n",
       "  'verbose': 0,\n",
       "  'refit': True,\n",
       "  'intercept_scaling': 1.0,\n",
       "  'multi_class': 'auto',\n",
       "  'random_state': None,\n",
       "  'l1_ratios': None},\n",
       " {'loss': 'hinge',\n",
       "  'penalty': 'l2',\n",
       "  'alpha': 0.0001,\n",
       "  'l1_ratio': 0.15,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'epsilon': 0.1,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'learning_rate': 'optimal',\n",
       "  'eta0': 0.0,\n",
       "  'power_t': 0.5,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'class_weight': None,\n",
       "  'warm_start': False,\n",
       "  'average': False},\n",
       " {'penalty': None,\n",
       "  'alpha': 0.0001,\n",
       "  'l1_ratio': 0.15,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'eta0': 1.0,\n",
       "  'n_jobs': None,\n",
       "  'random_state': 0,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'class_weight': None,\n",
       "  'warm_start': False},\n",
       " {'C': 1.0,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'loss': 'hinge',\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'average': False},\n",
       " {'alphas': (0.1, 1.0, 10.0),\n",
       "  'fit_intercept': True,\n",
       "  'scoring': None,\n",
       "  'cv': None,\n",
       "  'class_weight': None,\n",
       "  'store_cv_values': False},\n",
       " {'penalty': 'l2',\n",
       "  'loss': 'squared_hinge',\n",
       "  'dual': 'warn',\n",
       "  'tol': 0.0001,\n",
       "  'C': 1.0,\n",
       "  'multi_class': 'ovr',\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'class_weight': None,\n",
       "  'verbose': 0,\n",
       "  'random_state': None,\n",
       "  'max_iter': 1000},\n",
       " {'C': 1.0,\n",
       "  'kernel': 'rbf',\n",
       "  'degree': 3,\n",
       "  'gamma': 'scale',\n",
       "  'coef0': 0.0,\n",
       "  'shrinking': True,\n",
       "  'probability': False,\n",
       "  'tol': 0.001,\n",
       "  'cache_size': 200,\n",
       "  'class_weight': None,\n",
       "  'verbose': False,\n",
       "  'max_iter': -1,\n",
       "  'decision_function_shape': 'ovr',\n",
       "  'break_ties': False,\n",
       "  'random_state': None},\n",
       " {'nu': 0.5,\n",
       "  'kernel': 'rbf',\n",
       "  'degree': 3,\n",
       "  'gamma': 'scale',\n",
       "  'coef0': 0.0,\n",
       "  'shrinking': True,\n",
       "  'probability': False,\n",
       "  'tol': 0.001,\n",
       "  'cache_size': 200,\n",
       "  'class_weight': None,\n",
       "  'verbose': False,\n",
       "  'max_iter': -1,\n",
       "  'decision_function_shape': 'ovr',\n",
       "  'break_ties': False,\n",
       "  'random_state': None},\n",
       " {'criterion': 'gini',\n",
       "  'splitter': 'best',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': None,\n",
       "  'random_state': None,\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0},\n",
       " {'n_estimators': 100,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'bootstrap': True,\n",
       "  'oob_score': False,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0,\n",
       "  'max_samples': None},\n",
       " {'n_estimators': 100,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'bootstrap': False,\n",
       "  'oob_score': False,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0,\n",
       "  'max_samples': None},\n",
       " {'loss': 'log_loss',\n",
       "  'learning_rate': 0.1,\n",
       "  'n_estimators': 100,\n",
       "  'subsample': 1.0,\n",
       "  'criterion': 'friedman_mse',\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_depth': 3,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'init': None,\n",
       "  'random_state': None,\n",
       "  'max_features': None,\n",
       "  'verbose': 0,\n",
       "  'max_leaf_nodes': None,\n",
       "  'warm_start': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': None,\n",
       "  'tol': 0.0001,\n",
       "  'ccp_alpha': 0.0},\n",
       " {'loss': 'log_loss',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_iter': 100,\n",
       "  'max_leaf_nodes': 31,\n",
       "  'max_depth': None,\n",
       "  'min_samples_leaf': 20,\n",
       "  'l2_regularization': 0.0,\n",
       "  'max_bins': 255,\n",
       "  'categorical_features': None,\n",
       "  'monotonic_cst': None,\n",
       "  'interaction_cst': None,\n",
       "  'warm_start': False,\n",
       "  'early_stopping': 'auto',\n",
       "  'scoring': 'loss',\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 10,\n",
       "  'tol': 1e-07,\n",
       "  'verbose': 0,\n",
       "  'random_state': None,\n",
       "  'class_weight': None},\n",
       " {'n_neighbors': 5,\n",
       "  'weights': 'uniform',\n",
       "  'algorithm': 'auto',\n",
       "  'leaf_size': 30,\n",
       "  'p': 2,\n",
       "  'metric': 'minkowski',\n",
       "  'metric_params': None,\n",
       "  'n_jobs': None},\n",
       " {'hidden_layer_sizes': (100,),\n",
       "  'activation': 'relu',\n",
       "  'solver': 'adam',\n",
       "  'alpha': 0.0001,\n",
       "  'batch_size': 'auto',\n",
       "  'learning_rate': 'constant',\n",
       "  'learning_rate_init': 0.001,\n",
       "  'power_t': 0.5,\n",
       "  'max_iter': 200,\n",
       "  'shuffle': True,\n",
       "  'random_state': None,\n",
       "  'tol': 0.0001,\n",
       "  'verbose': False,\n",
       "  'warm_start': False,\n",
       "  'momentum': 0.9,\n",
       "  'nesterovs_momentum': True,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'beta_1': 0.9,\n",
       "  'beta_2': 0.999,\n",
       "  'epsilon': 1e-08,\n",
       "  'n_iter_no_change': 10,\n",
       "  'max_fun': 15000},\n",
       " {'priors': None, 'var_smoothing': 1e-09},\n",
       " {'alpha': 1.0,\n",
       "  'force_alpha': 'warn',\n",
       "  'binarize': 0.0,\n",
       "  'fit_prior': True,\n",
       "  'class_prior': None}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keywords = set()\n",
    "def get_kwargs(function):\n",
    "    signature = inspect.signature(function)\n",
    "    parameters = signature.parameters\n",
    "    keywords = {k: v.default for k, v in parameters.items() if v.default is not inspect.Parameter.empty}\n",
    "    all_keywords.update(keywords.keys())\n",
    "    return keywords\n",
    "\n",
    "[get_kwargs(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C',\n",
       " 'Cs',\n",
       " 'activation',\n",
       " 'algorithm',\n",
       " 'alpha',\n",
       " 'alphas',\n",
       " 'average',\n",
       " 'batch_size',\n",
       " 'beta_1',\n",
       " 'beta_2',\n",
       " 'binarize',\n",
       " 'bootstrap',\n",
       " 'break_ties',\n",
       " 'cache_size',\n",
       " 'categorical_features',\n",
       " 'ccp_alpha',\n",
       " 'class_prior',\n",
       " 'class_weight',\n",
       " 'coef0',\n",
       " 'criterion',\n",
       " 'cv',\n",
       " 'decision_function_shape',\n",
       " 'degree',\n",
       " 'dual',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'eta0',\n",
       " 'fit_intercept',\n",
       " 'fit_prior',\n",
       " 'force_alpha',\n",
       " 'gamma',\n",
       " 'hidden_layer_sizes',\n",
       " 'init',\n",
       " 'interaction_cst',\n",
       " 'intercept_scaling',\n",
       " 'kernel',\n",
       " 'l1_ratio',\n",
       " 'l1_ratios',\n",
       " 'l2_regularization',\n",
       " 'leaf_size',\n",
       " 'learning_rate',\n",
       " 'learning_rate_init',\n",
       " 'loss',\n",
       " 'max_bins',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_fun',\n",
       " 'max_iter',\n",
       " 'max_leaf_nodes',\n",
       " 'max_samples',\n",
       " 'metric',\n",
       " 'metric_params',\n",
       " 'min_impurity_decrease',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'momentum',\n",
       " 'monotonic_cst',\n",
       " 'multi_class',\n",
       " 'n_estimators',\n",
       " 'n_iter_no_change',\n",
       " 'n_jobs',\n",
       " 'n_neighbors',\n",
       " 'nesterovs_momentum',\n",
       " 'nu',\n",
       " 'oob_score',\n",
       " 'p',\n",
       " 'penalty',\n",
       " 'power_t',\n",
       " 'priors',\n",
       " 'probability',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'scoring',\n",
       " 'shrinking',\n",
       " 'shuffle',\n",
       " 'solver',\n",
       " 'splitter',\n",
       " 'store_cv_values',\n",
       " 'subsample',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'var_smoothing',\n",
       " 'verbose',\n",
       " 'warm_start',\n",
       " 'weights'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegressionCV'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curried_models[0].func.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:41<?, ?it/s]\n",
      "/home/rstrange/anaconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "Processing BernoulliNB: 100%|██████████| 17/17 [00:20<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(curried_models))\n",
    "all_models = []\n",
    "for curried_model in curried_models:\n",
    "    pbar.set_description(f\"Processing {curried_model.func.__name__}\")\n",
    "    all_models.append(train_model(curried_model(), train_X, train_y, test_X, test_y))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  all_models = [train_model(model(), train_X, train_y, test_X, test_y) for model in curried_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------+--------------------+\n",
      "|             Model              |      Accuracy      |      Log Loss      |\n",
      "+--------------------------------+--------------------+--------------------+\n",
      "|      LogisticRegressionCV      | 0.9882352941176471 | 0.4240429810484373 |\n",
      "|         SGDClassifier          | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|           Perceptron           | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|  PassiveAggressiveClassifier   | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|       RidgeClassifierCV        | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|           LinearSVC            | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|              SVC               | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|             NuSVC              | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|     DecisionTreeClassifier     | 0.9411764705882353 | 2.1202149052421855 |\n",
      "|     RandomForestClassifier     | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|      ExtraTreesClassifier      | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|   GradientBoostingClassifier   | 0.9647058823529412 | 1.2721289431453116 |\n",
      "| HistGradientBoostingClassifier | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|      KNeighborsClassifier      | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|         MLPClassifier          | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|           GaussianNB           | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|          BernoulliNB           | 0.9647058823529412 | 1.2721289431453116 |\n",
      "+--------------------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "binary_classification_table = PrettyTable()\n",
    "binary_classification_table.field_names = [\"Model\", \"Accuracy\", \"Log Loss\"]\n",
    "for curried_model in all_models:\n",
    "    binary_classification_table.add_row([curried_model.model.__class__.__name__, curried_model.accuracy, curried_model.log_loss])\n",
    "\n",
    "print(binary_classification_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_df = load_iris(as_frame=True).frame\n",
    "\n",
    "iris_df = iris_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "y = iris_df.pop('target').values\n",
    "X_df = iris_df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for column in X_df.columns:\n",
    "    X_df[column] = scaler.fit_transform(X_df[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_df.values, y, test_size=0.3, random_state=42)\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X, test_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier, Perceptron, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegressionCV,\n",
    "    SGDClassifier,\n",
    "    Perceptron,\n",
    "    PassiveAggressiveClassifier,\n",
    "    RidgeClassifierCV,\n",
    "    SVC,\n",
    "    NuSVC,\n",
    "    LinearSVC,\n",
    "    KNeighborsClassifier,\n",
    "    RadiusNeighborsClassifier,\n",
    "    NearestCentroid,\n",
    "    GaussianProcessClassifier,\n",
    "    DecisionTreeClassifier,\n",
    "    ExtraTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GaussianNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    BernoulliNB,\n",
    "    MLPClassifier,\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics = namedtuple('model_and_metrics', ['model', 'accuracy', 'log_loss', 'confusion_matrix'])\n",
    "\n",
    "def train_model(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    cm = confusion_matrix(test_y, pred_y)\n",
    "    return model_and_metrics(model, accuracy_score(test_y, pred_y), log_loss(test_y, pred_y), cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "curried_models = [add_appropriate_kwargs(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
