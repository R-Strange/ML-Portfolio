{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from collections import namedtuple, defaultdict\n",
    "import inspect\n",
    "import configparser\n",
    "from prettytable import PrettyTable\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classification_model_parameters = {\n",
    "    \"max_iter\": ast.literal_eval(config[\"CLASSIFICATION\"][\"maxiterations\"]),\n",
    "    \"cv\": ast.literal_eval(config[\"CLASSIFICATION\"][\"cvfolds\"]),\n",
    "    \"tolerance\": ast.literal_eval(config[\"CLASSIFICATION\"][\"tolerance\"]),\n",
    "    \"random_state\": ast.literal_eval(config[\"CLASSIFICATION\"][\"randomstate\"]),\n",
    "    \"verbose\": ast.literal_eval(config[\"CLASSIFICATION\"][\"verbose\"]),\n",
    "}\n",
    "\n",
    "binary_classification_model_parameters = defaultdict(lambda: None, binary_classification_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classification Models\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "1. `LogisticRegression`: Logistic Regression (aka logit, MaxEnt) classifier.\n",
    "\n",
    "2. `SGDClassifier`: Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n",
    "\n",
    "3. `Perceptron`: The perceptron is a simple classification algorithm suitable for large scale learning.\n",
    "\n",
    "4. `PassiveAggressiveClassifier`: Passive Aggressive Classifier.\n",
    "\n",
    "5. `RidgeClassifier`: Classifier using Ridge regression.\n",
    "\n",
    "6. `RidgeClassifierCV`: Ridge classifier with built-in cross-validation.\n",
    "\n",
    "7. `LinearSVC`: Linear Support Vector Classification.\n",
    "\n",
    "8. `SVC`: C-Support Vector Classification.\n",
    "\n",
    "9. `NuSVC`: Nu-Support Vector Classification.\n",
    "\n",
    "10. `DecisionTreeClassifier`: A decision tree classifier.\n",
    "\n",
    "11. `RandomForestClassifier`: A random forest classifier.\n",
    "\n",
    "12. `ExtraTreesClassifier`: An extra-trees classifier.\n",
    "\n",
    "13. `GradientBoostingClassifier`: Gradient Boosting for classification.\n",
    "\n",
    "14. `HistGradientBoostingClassifier`: Histogram-based Gradient Boosting Classification Tree.\n",
    "\n",
    "15. `AdaBoostClassifier`: An AdaBoost classifier.\n",
    "\n",
    "16. `BaggingClassifier`: A Bagging classifier.\n",
    "\n",
    "17. `VotingClassifier`: Soft Voting/Majority Rule classifier for unfitted estimators.\n",
    "\n",
    "18. `StackingClassifier`: Stacking classifier for unfitted estimators.\n",
    "\n",
    "19. `KNeighborsClassifier`: Classifier implementing the k-nearest neighbors vote.\n",
    "\n",
    "20. `RadiusNeighborsClassifier`: Classifier implementing a vote among neighbors within a given radius.\n",
    "\n",
    "21. `MLPClassifier`: Multi-layer Perceptron classifier.\n",
    "\n",
    "22. `GaussianNB`: Gaussian Naive Bayes (GaussianNB).\n",
    "\n",
    "23. `BernoulliNB`: Naive Bayes classifier for multivariate Bernoulli models.\n",
    "\n",
    "24. `ComplementNB`: The Complement Naive Bayes classifier.\n",
    "\n",
    "25. `MultinomialNB`: Naive Bayes classifier for multinomial models.\n",
    "\n",
    "Please refer to the [Scikit-learn documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) for more details on each of these methods.\n",
    "\n",
    "\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "iris_df = load_breast_cancer(as_frame=True).frame\n",
    "\n",
    "y = iris_df.pop('target').values\n",
    "X_df = iris_df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for column in X_df.columns:\n",
    "    X_df[column] = scaler.fit_transform(X_df[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_df.values, y, test_size=0.3, random_state=42)\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X, test_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier, Perceptron, PassiveAggressiveClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_appropriate_kwargs(function, config_parameters):\n",
    "    signature = inspect.signature(function)\n",
    "    parameters = signature.parameters\n",
    "    keywords = {k: v.default for k, v in parameters.items() if v.default is not inspect.Parameter.empty}\n",
    "\n",
    "    for key, _ in keywords.items():\n",
    "        if key in config_parameters:\n",
    "            keywords[key] = config_parameters[key]\n",
    "\n",
    "    return partial(function, **keywords)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics = namedtuple('model_and_metrics', ['model', 'accuracy', 'log_loss', 'confusion_matrix'])\n",
    "\n",
    "def train_model(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    cm = confusion_matrix(test_y, pred_y)\n",
    "    return model_and_metrics(model, accuracy_score(test_y, pred_y), log_loss(test_y, pred_y), cm)\n",
    "\n",
    "models = [\n",
    "    LogisticRegressionCV,\n",
    "    SGDClassifier,\n",
    "    Perceptron,\n",
    "    PassiveAggressiveClassifier,\n",
    "    RidgeClassifierCV,\n",
    "    LinearSVC,\n",
    "    SVC,\n",
    "    NuSVC,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    MLPClassifier,\n",
    "    GaussianNB,\n",
    "    BernoulliNB,\n",
    "]\n",
    "\n",
    "curried_models = [add_appropriate_kwargs(model, binary_classification_model_parameters) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Cs': 10,\n",
       "  'fit_intercept': True,\n",
       "  'cv': None,\n",
       "  'dual': False,\n",
       "  'penalty': 'l2',\n",
       "  'scoring': None,\n",
       "  'solver': 'lbfgs',\n",
       "  'tol': 0.0001,\n",
       "  'max_iter': 100,\n",
       "  'class_weight': None,\n",
       "  'n_jobs': None,\n",
       "  'verbose': 0,\n",
       "  'refit': True,\n",
       "  'intercept_scaling': 1.0,\n",
       "  'multi_class': 'auto',\n",
       "  'random_state': None,\n",
       "  'l1_ratios': None},\n",
       " {'loss': 'hinge',\n",
       "  'penalty': 'l2',\n",
       "  'alpha': 0.0001,\n",
       "  'l1_ratio': 0.15,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'epsilon': 0.1,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'learning_rate': 'optimal',\n",
       "  'eta0': 0.0,\n",
       "  'power_t': 0.5,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'class_weight': None,\n",
       "  'warm_start': False,\n",
       "  'average': False},\n",
       " {'penalty': None,\n",
       "  'alpha': 0.0001,\n",
       "  'l1_ratio': 0.15,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'eta0': 1.0,\n",
       "  'n_jobs': None,\n",
       "  'random_state': 0,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'class_weight': None,\n",
       "  'warm_start': False},\n",
       " {'C': 1.0,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000,\n",
       "  'tol': 0.001,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 5,\n",
       "  'shuffle': True,\n",
       "  'verbose': 0,\n",
       "  'loss': 'hinge',\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'average': False},\n",
       " {'alphas': (0.1, 1.0, 10.0),\n",
       "  'fit_intercept': True,\n",
       "  'scoring': None,\n",
       "  'cv': None,\n",
       "  'class_weight': None,\n",
       "  'store_cv_values': False},\n",
       " {'penalty': 'l2',\n",
       "  'loss': 'squared_hinge',\n",
       "  'dual': 'warn',\n",
       "  'tol': 0.0001,\n",
       "  'C': 1.0,\n",
       "  'multi_class': 'ovr',\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'class_weight': None,\n",
       "  'verbose': 0,\n",
       "  'random_state': None,\n",
       "  'max_iter': 1000},\n",
       " {'C': 1.0,\n",
       "  'kernel': 'rbf',\n",
       "  'degree': 3,\n",
       "  'gamma': 'scale',\n",
       "  'coef0': 0.0,\n",
       "  'shrinking': True,\n",
       "  'probability': False,\n",
       "  'tol': 0.001,\n",
       "  'cache_size': 200,\n",
       "  'class_weight': None,\n",
       "  'verbose': False,\n",
       "  'max_iter': -1,\n",
       "  'decision_function_shape': 'ovr',\n",
       "  'break_ties': False,\n",
       "  'random_state': None},\n",
       " {'nu': 0.5,\n",
       "  'kernel': 'rbf',\n",
       "  'degree': 3,\n",
       "  'gamma': 'scale',\n",
       "  'coef0': 0.0,\n",
       "  'shrinking': True,\n",
       "  'probability': False,\n",
       "  'tol': 0.001,\n",
       "  'cache_size': 200,\n",
       "  'class_weight': None,\n",
       "  'verbose': False,\n",
       "  'max_iter': -1,\n",
       "  'decision_function_shape': 'ovr',\n",
       "  'break_ties': False,\n",
       "  'random_state': None},\n",
       " {'criterion': 'gini',\n",
       "  'splitter': 'best',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': None,\n",
       "  'random_state': None,\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0},\n",
       " {'n_estimators': 100,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'bootstrap': True,\n",
       "  'oob_score': False,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0,\n",
       "  'max_samples': None},\n",
       " {'n_estimators': 100,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'bootstrap': False,\n",
       "  'oob_score': False,\n",
       "  'n_jobs': None,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False,\n",
       "  'class_weight': None,\n",
       "  'ccp_alpha': 0.0,\n",
       "  'max_samples': None},\n",
       " {'loss': 'log_loss',\n",
       "  'learning_rate': 0.1,\n",
       "  'n_estimators': 100,\n",
       "  'subsample': 1.0,\n",
       "  'criterion': 'friedman_mse',\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_weight_fraction_leaf': 0.0,\n",
       "  'max_depth': 3,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'init': None,\n",
       "  'random_state': None,\n",
       "  'max_features': None,\n",
       "  'verbose': 0,\n",
       "  'max_leaf_nodes': None,\n",
       "  'warm_start': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': None,\n",
       "  'tol': 0.0001,\n",
       "  'ccp_alpha': 0.0},\n",
       " {'loss': 'log_loss',\n",
       "  'learning_rate': 0.1,\n",
       "  'max_iter': 100,\n",
       "  'max_leaf_nodes': 31,\n",
       "  'max_depth': None,\n",
       "  'min_samples_leaf': 20,\n",
       "  'l2_regularization': 0.0,\n",
       "  'max_bins': 255,\n",
       "  'categorical_features': None,\n",
       "  'monotonic_cst': None,\n",
       "  'interaction_cst': None,\n",
       "  'warm_start': False,\n",
       "  'early_stopping': 'auto',\n",
       "  'scoring': 'loss',\n",
       "  'validation_fraction': 0.1,\n",
       "  'n_iter_no_change': 10,\n",
       "  'tol': 1e-07,\n",
       "  'verbose': 0,\n",
       "  'random_state': None,\n",
       "  'class_weight': None},\n",
       " {'n_neighbors': 5,\n",
       "  'weights': 'uniform',\n",
       "  'algorithm': 'auto',\n",
       "  'leaf_size': 30,\n",
       "  'p': 2,\n",
       "  'metric': 'minkowski',\n",
       "  'metric_params': None,\n",
       "  'n_jobs': None},\n",
       " {'hidden_layer_sizes': (100,),\n",
       "  'activation': 'relu',\n",
       "  'solver': 'adam',\n",
       "  'alpha': 0.0001,\n",
       "  'batch_size': 'auto',\n",
       "  'learning_rate': 'constant',\n",
       "  'learning_rate_init': 0.001,\n",
       "  'power_t': 0.5,\n",
       "  'max_iter': 200,\n",
       "  'shuffle': True,\n",
       "  'random_state': None,\n",
       "  'tol': 0.0001,\n",
       "  'verbose': False,\n",
       "  'warm_start': False,\n",
       "  'momentum': 0.9,\n",
       "  'nesterovs_momentum': True,\n",
       "  'early_stopping': False,\n",
       "  'validation_fraction': 0.1,\n",
       "  'beta_1': 0.9,\n",
       "  'beta_2': 0.999,\n",
       "  'epsilon': 1e-08,\n",
       "  'n_iter_no_change': 10,\n",
       "  'max_fun': 15000},\n",
       " {'priors': None, 'var_smoothing': 1e-09},\n",
       " {'alpha': 1.0,\n",
       "  'force_alpha': 'warn',\n",
       "  'binarize': 0.0,\n",
       "  'fit_prior': True,\n",
       "  'class_prior': None}]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keywords = set()\n",
    "def get_kwargs(function):\n",
    "    signature = inspect.signature(function)\n",
    "    parameters = signature.parameters\n",
    "    keywords = {k: v.default for k, v in parameters.items() if v.default is not inspect.Parameter.empty}\n",
    "    all_keywords.update(keywords.keys())\n",
    "    return keywords\n",
    "\n",
    "[get_kwargs(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C',\n",
       " 'Cs',\n",
       " 'activation',\n",
       " 'algorithm',\n",
       " 'alpha',\n",
       " 'alphas',\n",
       " 'average',\n",
       " 'batch_size',\n",
       " 'beta_1',\n",
       " 'beta_2',\n",
       " 'binarize',\n",
       " 'bootstrap',\n",
       " 'break_ties',\n",
       " 'cache_size',\n",
       " 'categorical_features',\n",
       " 'ccp_alpha',\n",
       " 'class_prior',\n",
       " 'class_weight',\n",
       " 'coef0',\n",
       " 'criterion',\n",
       " 'cv',\n",
       " 'decision_function_shape',\n",
       " 'degree',\n",
       " 'dual',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'eta0',\n",
       " 'fit_intercept',\n",
       " 'fit_prior',\n",
       " 'force_alpha',\n",
       " 'gamma',\n",
       " 'hidden_layer_sizes',\n",
       " 'init',\n",
       " 'interaction_cst',\n",
       " 'intercept_scaling',\n",
       " 'kernel',\n",
       " 'l1_ratio',\n",
       " 'l1_ratios',\n",
       " 'l2_regularization',\n",
       " 'leaf_size',\n",
       " 'learning_rate',\n",
       " 'learning_rate_init',\n",
       " 'loss',\n",
       " 'max_bins',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_fun',\n",
       " 'max_iter',\n",
       " 'max_leaf_nodes',\n",
       " 'max_samples',\n",
       " 'metric',\n",
       " 'metric_params',\n",
       " 'min_impurity_decrease',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'momentum',\n",
       " 'monotonic_cst',\n",
       " 'multi_class',\n",
       " 'n_estimators',\n",
       " 'n_iter_no_change',\n",
       " 'n_jobs',\n",
       " 'n_neighbors',\n",
       " 'nesterovs_momentum',\n",
       " 'nu',\n",
       " 'oob_score',\n",
       " 'p',\n",
       " 'penalty',\n",
       " 'power_t',\n",
       " 'priors',\n",
       " 'probability',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'scoring',\n",
       " 'shrinking',\n",
       " 'shuffle',\n",
       " 'solver',\n",
       " 'splitter',\n",
       " 'store_cv_values',\n",
       " 'subsample',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'var_smoothing',\n",
       " 'verbose',\n",
       " 'warm_start',\n",
       " 'weights'}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LinearSVC:  29%|██▉       | 5/17 [00:01<00:02,  5.28it/s]                  /Users/richardstrange/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "Processing BernoulliNB: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s]                   \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(curried_models))\n",
    "all_models = []\n",
    "for curried_model in curried_models:\n",
    "    pbar.set_description(f\"Processing {curried_model.func.__name__}\")\n",
    "    all_models.append(train_model(curried_model(), train_X, train_y, test_X, test_y))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  all_models = [train_model(model(), train_X, train_y, test_X, test_y) for model in curried_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------+--------------------+\n",
      "|             Model              |      Accuracy      |      Log Loss      |\n",
      "+--------------------------------+--------------------+--------------------+\n",
      "|      LogisticRegressionCV      | 0.9882352941176471 | 0.4240429810484373 |\n",
      "|         SGDClassifier          | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|           Perceptron           | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|  PassiveAggressiveClassifier   | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|       RidgeClassifierCV        | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|           LinearSVC            | 0.9764705882352941 | 0.8480859620968744 |\n",
      "|              SVC               | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|             NuSVC              | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|     DecisionTreeClassifier     | 0.9411764705882353 | 2.1202149052421855 |\n",
      "|     RandomForestClassifier     | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|      ExtraTreesClassifier      | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|   GradientBoostingClassifier   | 0.9647058823529412 | 1.2721289431453116 |\n",
      "| HistGradientBoostingClassifier | 0.9529411764705882 | 1.6961719241937483 |\n",
      "|      KNeighborsClassifier      | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|         MLPClassifier          | 0.9647058823529412 | 1.2721289431453116 |\n",
      "|           GaussianNB           | 0.9294117647058824 | 2.5442578862906227 |\n",
      "|          BernoulliNB           | 0.9647058823529412 | 1.2721289431453116 |\n",
      "+--------------------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "binary_classification_table = PrettyTable()\n",
    "binary_classification_table.field_names = [\"Model\", \"Accuracy\", \"Log Loss\"]\n",
    "for curried_model in all_models:\n",
    "    binary_classification_table.add_row([curried_model.model.__class__.__name__, curried_model.accuracy, curried_model.log_loss])\n",
    "\n",
    "print(binary_classification_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_df = load_iris(as_frame=True).frame\n",
    "\n",
    "iris_df = iris_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "y = iris_df.pop('target').values\n",
    "X_df = iris_df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for column in X_df.columns:\n",
    "    X_df[column] = scaler.fit_transform(X_df[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_df.values, y, test_size=0.3, random_state=42)\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X, test_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_classification_model_parameters = {\n",
    "    \"max_iter\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"maxiterations\"]),\n",
    "    \"cv\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"cvfolds\"]),\n",
    "    \"tolerance\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"tolerance\"]),\n",
    "    \"random_state\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"randomstate\"]),\n",
    "    \"verbose\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"verbose\"]),\n",
    "    \"multi_class\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"multiclass\"]),\n",
    "    \"labels\": ast.literal_eval(config[\"MULTICLASS CLASSIFICATION\"][\"labels\"]),\n",
    "}\n",
    "\n",
    "multiclass_classification_model_parameters = defaultdict(lambda: None, multiclass_classification_model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'max_iter': 10000,\n",
       "             'cv': 5,\n",
       "             'tolerance': 0.0001,\n",
       "             'random_state': 42,\n",
       "             'verbose': False,\n",
       "             'multi_class': 'multinomial',\n",
       "             'labels': [0, 1, 2]})"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_classification_model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier, Perceptron, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegressionCV,\n",
    "    SGDClassifier,\n",
    "    Perceptron,\n",
    "    PassiveAggressiveClassifier,\n",
    "    RidgeClassifierCV,\n",
    "    SVC,\n",
    "    NuSVC,\n",
    "    LinearSVC,\n",
    "    KNeighborsClassifier,\n",
    "    RadiusNeighborsClassifier,\n",
    "    NearestCentroid,\n",
    "    GaussianProcessClassifier,\n",
    "    DecisionTreeClassifier,\n",
    "    ExtraTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GaussianNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    BernoulliNB,\n",
    "    MLPClassifier,\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics = namedtuple('model_and_metrics', ['model', 'accuracy', 'confusion_matrix'])\n",
    "\n",
    "def train_model(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    cm = confusion_matrix(y_true=test_y, y_pred=pred_y)\n",
    "    return model_and_metrics(model, accuracy_score(y_true=test_y, y_pred=pred_y),  cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "curried_models = [add_appropriate_kwargs(model, multiclass_classification_model_parameters) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'sklearn.linear_model._logistic.LogisticRegressionCV'>, Cs=10, fit_intercept=True, cv=5, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=10000, class_weight=None, n_jobs=None, verbose=False, refit=True, intercept_scaling=1.0, multi_class='multinomial', random_state=42, l1_ratios=None)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curried_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LogisticRegressionCV:   0%|          | 0/29 [03:17<?, ?it/s]\n",
      "Processing LinearSVC:  24%|██▍       | 7/29 [00:00<00:02,  8.19it/s]                  "
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'multi_class' parameter of LinearSVC must be a str among {'crammer_singer', 'ovr'}. Got 'multinomial' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/richardstrange/Library/CloudStorage/Dropbox/5 - GitHub local Repositories/ML Portfolio/simple techniques/Simple Classifications.ipynb Cell 26\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m curried_model \u001b[39min\u001b[39;00m curried_models:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mcurried_model\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     multiclass_classification_models\u001b[39m.\u001b[39mappend(train_model(curried_model(), train_X, train_y, test_X, test_y))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/richardstrange/Library/CloudStorage/Dropbox/5 - GitHub local Repositories/ML Portfolio/simple techniques/Simple Classifications.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, train_X, train_y, test_X, test_y):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pred_y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y201sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cm \u001b[39m=\u001b[39m confusion_matrix(y_true\u001b[39m=\u001b[39mtest_y, y_pred\u001b[39m=\u001b[39mpred_y)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1141\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1142\u001b[0m )\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1145\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[1;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    631\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[1;32m    640\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    641\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    642\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'multi_class' parameter of LinearSVC must be a str among {'crammer_singer', 'ovr'}. Got 'multinomial' instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LinearSVC:  24%|██▍       | 7/29 [00:12<00:02,  8.19it/s]"
     ]
    }
   ],
   "source": [
    "multiclass_classification_models = []\n",
    "pbar = tqdm(total=len(curried_models))\n",
    "for curried_model in curried_models:\n",
    "    pbar.set_description(f\"Processing {curried_model.func.__name__}\")\n",
    "    multiclass_classification_models.append(train_model(curried_model(), train_X, train_y, test_X, test_y))\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegressionCV(max_iter=1000, cv=5, random_state=42, multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=1000, multi_class=&#x27;multinomial&#x27;,\n",
       "                     random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=1000, multi_class=&#x27;multinomial&#x27;,\n",
       "                     random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=1000, multi_class='multinomial',\n",
       "                     random_state=42)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function log_loss in module sklearn.metrics._classification:\n",
      "\n",
      "log_loss(y_true, y_pred, *, eps='auto', normalize=True, sample_weight=None, labels=None)\n",
      "    Log loss, aka logistic loss or cross-entropy loss.\n",
      "    \n",
      "    This is the loss function used in (multinomial) logistic regression\n",
      "    and extensions of it such as neural networks, defined as the negative\n",
      "    log-likelihood of a logistic model that returns ``y_pred`` probabilities\n",
      "    for its training data ``y_true``.\n",
      "    The log loss is only defined for two or more labels.\n",
      "    For a single sample with true label :math:`y \\in \\{0,1\\}` and\n",
      "    a probability estimate :math:`p = \\operatorname{Pr}(y = 1)`, the log\n",
      "    loss is:\n",
      "    \n",
      "    .. math::\n",
      "        L_{\\log}(y, p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n",
      "    \n",
      "    Read more in the :ref:`User Guide <log_loss>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like or label indicator matrix\n",
      "        Ground truth (correct) labels for n_samples samples.\n",
      "    \n",
      "    y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)\n",
      "        Predicted probabilities, as returned by a classifier's\n",
      "        predict_proba method. If ``y_pred.shape = (n_samples,)``\n",
      "        the probabilities provided are assumed to be that of the\n",
      "        positive class. The labels in ``y_pred`` are assumed to be\n",
      "        ordered alphabetically, as done by\n",
      "        :class:`~sklearn.preprocessing.LabelBinarizer`.\n",
      "    \n",
      "    eps : float or \"auto\", default=\"auto\"\n",
      "        Log loss is undefined for p=0 or p=1, so probabilities are\n",
      "        clipped to `max(eps, min(1 - eps, p))`. The default will depend on the\n",
      "        data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "           The default value changed from `1e-15` to `\"auto\"` that is\n",
      "           equivalent to `np.finfo(y_pred.dtype).eps`.\n",
      "    \n",
      "        .. deprecated:: 1.3\n",
      "           `eps` is deprecated in 1.3 and will be removed in 1.5.\n",
      "    \n",
      "    normalize : bool, default=True\n",
      "        If true, return the mean loss per sample.\n",
      "        Otherwise, return the sum of the per-sample losses.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    labels : array-like, default=None\n",
      "        If not provided, labels will be inferred from y_true. If ``labels``\n",
      "        is ``None`` and ``y_pred`` has shape (n_samples,) the labels are\n",
      "        assumed to be binary and are inferred from ``y_true``.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    loss : float\n",
      "        Log loss, aka logistic loss or cross-entropy loss.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The logarithm used is the natural logarithm (base-e).\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,\n",
      "    p. 209.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import log_loss\n",
      "    >>> log_loss([\"spam\", \"ham\", \"ham\", \"spam\"],\n",
      "    ...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])\n",
      "    0.21616...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes in labels is different from that in y_pred. Classes found in labels: [0 1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/richardstrange/Library/CloudStorage/Dropbox/5 - GitHub local Repositories/ML Portfolio/simple techniques/Simple Classifications.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/richardstrange/Library/CloudStorage/Dropbox/5%20-%20GitHub%20local%20Repositories/ML%20Portfolio/simple%20techniques/Simple%20Classifications.ipynb#Y222sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m log_loss(test_y, y_pred, labels\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml-portfolio/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2913\u001b[0m, in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2903\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39my_true and y_pred contain different number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mclasses \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m. Please provide the true \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             )\n\u001b[1;32m   2911\u001b[0m         )\n\u001b[1;32m   2912\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe number of classes in labels is different \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2915\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfrom that in y_pred. Classes found in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlabels: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(lb\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m   2917\u001b[0m         )\n\u001b[1;32m   2919\u001b[0m \u001b[39m# Renormalize\u001b[39;00m\n\u001b[1;32m   2920\u001b[0m y_pred_sum \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes in labels is different from that in y_pred. Classes found in labels: [0 1 2]"
     ]
    }
   ],
   "source": [
    "log_loss(test_y, y_pred, labels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'sklearn.linear_model._logistic.LogisticRegressionCV'>, Cs=10, fit_intercept=True, cv=5, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=10000, class_weight=None, n_jobs=None, verbose=False, refit=True, intercept_scaling=1.0, multi_class='auto', random_state=42, l1_ratios=None)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curried_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04741578e-06, 2.85604443e-02, 9.71438508e-01],\n",
       "       [9.96921010e-01, 3.07899024e-03, 2.50170077e-14],\n",
       "       [9.99935442e-01, 6.45578167e-05, 5.49210809e-18],\n",
       "       [9.99816331e-01, 1.83669411e-04, 3.10237113e-17],\n",
       "       [9.96428092e-01, 3.57190798e-03, 7.96396729e-16],\n",
       "       [9.96586544e-01, 3.41345632e-03, 3.42934519e-15],\n",
       "       [1.34950844e-03, 9.86331994e-01, 1.23184979e-02],\n",
       "       [3.77511672e-06, 3.25949964e-02, 9.67401228e-01],\n",
       "       [3.78253120e-08, 4.68999362e-03, 9.95309969e-01],\n",
       "       [5.16236747e-03, 9.94810778e-01, 2.68549347e-05],\n",
       "       [7.78957531e-05, 9.66759050e-01, 3.31630542e-02],\n",
       "       [9.99176831e-01, 8.23169227e-04, 1.68064591e-15],\n",
       "       [1.87590274e-12, 8.19217067e-05, 9.99918078e-01],\n",
       "       [3.75713422e-05, 9.40207134e-01, 5.97552947e-02],\n",
       "       [1.17997569e-09, 3.74100100e-03, 9.96258998e-01],\n",
       "       [2.66312305e-03, 9.97112203e-01, 2.24673885e-04],\n",
       "       [2.45591130e-06, 8.04774113e-02, 9.19520133e-01],\n",
       "       [9.96264870e-01, 3.73512989e-03, 1.51068758e-14],\n",
       "       [2.69922760e-04, 9.97168675e-01, 2.56140219e-03],\n",
       "       [8.12001674e-10, 5.50224405e-04, 9.99449775e-01],\n",
       "       [2.81956272e-03, 9.97052412e-01, 1.28025126e-04],\n",
       "       [1.42091011e-05, 9.51868391e-01, 4.81173996e-02]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
